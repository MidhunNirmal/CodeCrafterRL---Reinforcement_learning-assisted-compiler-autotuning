{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860ec9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['APP_NAME', '-funsafe-math-optimizations ',\n",
      "       '-fno-guess-branch-probability ', '-fno-ivopts ',\n",
      "       '-fno-tree-loop-optimize ', '-fno-inline-functions ',\n",
      "       '-funroll-all-loops ', '-O2 ', 'execution_time_1', 'execution_time_2',\n",
      "       'execution_time_3', 'execution_time_4', 'execution_time_5',\n",
      "       'code_size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"exec_times.csv\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a19bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45aaae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique application names:\n",
      "- linear-algebra/kernels/2mm\n",
      "- linear-algebra/kernels/3mm\n",
      "- linear-algebra/kernels/atax\n",
      "- linear-algebra/kernels/bicg\n",
      "- linear-algebra/kernels/doitgen\n",
      "- linear-algebra/kernels/mvt\n",
      "- linear-algebra/solvers/cholesky\n",
      "- linear-algebra/solvers/durbin\n",
      "- linear-algebra/solvers/gramschmidt\n",
      "- linear-algebra/solvers/lu\n",
      "- linear-algebra/solvers/ludcmp\n",
      "- linear-algebra/solvers/trisolv\n",
      "- linear-algebra/blas/gemm\n",
      "- linear-algebra/blas/gemver\n",
      "- linear-algebra/blas/gesummv\n",
      "- linear-algebra/blas/symm\n",
      "- linear-algebra/blas/syr2k\n",
      "- linear-algebra/blas/syrk\n",
      "- linear-algebra/blas/trmm\n",
      "- datamining/correlation\n",
      "- datamining/covariance\n",
      "- medley/deriche\n",
      "- medley/floyd-warshall\n",
      "- medley/nussinov\n",
      "- stencils/adi\n",
      "- stencils/fdtd-2d\n",
      "- stencils/heat-3d\n",
      "- stencils/jacobi-1d\n",
      "- stencils/jacobi-2d\n",
      "- stencils/seidel-2d\n"
     ]
    }
   ],
   "source": [
    "unique_apps = data['APP_NAME'].unique()\n",
    "print(\"Unique application names:\")\n",
    "for app in unique_apps:\n",
    "    print(f\"- {app}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524af673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Reading dataset: exec_times.csv\n",
      "\n",
      "‚úÖ Basic Info:\n",
      "Shape: (3840, 14)\n",
      "Columns: ['APP_NAME', '-funsafe-math-optimizations ', '-fno-guess-branch-probability ', '-fno-ivopts ', '-fno-tree-loop-optimize ', '-fno-inline-functions ', '-funroll-all-loops ', '-O2 ', 'execution_time_1', 'execution_time_2', 'execution_time_3', 'execution_time_4', 'execution_time_5', 'code_size']\n",
      "\n",
      "üìä Data Types:\n",
      "APP_NAME                           object\n",
      "-funsafe-math-optimizations        object\n",
      "-fno-guess-branch-probability      object\n",
      "-fno-ivopts                        object\n",
      "-fno-tree-loop-optimize            object\n",
      "-fno-inline-functions              object\n",
      "-funroll-all-loops                 object\n",
      "-O2                                object\n",
      "execution_time_1                  float64\n",
      "execution_time_2                  float64\n",
      "execution_time_3                  float64\n",
      "execution_time_4                  float64\n",
      "execution_time_5                    int64\n",
      "code_size                           int64\n",
      "dtype: object\n",
      "\n",
      "üßÆ Missing Values:\n",
      "APP_NAME                          0\n",
      "-funsafe-math-optimizations       0\n",
      "-fno-guess-branch-probability     0\n",
      "-fno-ivopts                       0\n",
      "-fno-tree-loop-optimize           0\n",
      "-fno-inline-functions             0\n",
      "-funroll-all-loops                0\n",
      "-O2                               0\n",
      "execution_time_1                  0\n",
      "execution_time_2                  0\n",
      "execution_time_3                  0\n",
      "execution_time_4                  0\n",
      "execution_time_5                  0\n",
      "code_size                         0\n",
      "dtype: int64\n",
      "\n",
      "üîë Unique Values Per Column:\n",
      "APP_NAME: 30 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: ['linear-algebra/kernels/2mm' 'linear-algebra/kernels/3mm'\n",
      " 'linear-algebra/kernels/atax' 'linear-algebra/kernels/bicg'\n",
      " 'linear-algebra/kernels/doitgen' 'linear-algebra/kernels/mvt'\n",
      " 'linear-algebra/solvers/cholesky' 'linear-algebra/solvers/durbin'\n",
      " 'linear-algebra/solvers/gramschmidt' 'linear-algebra/solvers/lu']\n",
      "-funsafe-math-optimizations : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-funsafe-math-optimizations ']\n",
      "-fno-guess-branch-probability : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-fno-guess-branch-probability ']\n",
      "-fno-ivopts : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-fno-ivopts ']\n",
      "-fno-tree-loop-optimize : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-fno-tree-loop-optimize ']\n",
      "-fno-inline-functions : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-fno-inline-functions ']\n",
      "-funroll-all-loops : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-funroll-all-loops ']\n",
      "-O2 : 2 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: ['X', '-O2 ']\n",
      "execution_time_1: 248 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: [2.0e-05 2.1e-05 2.3e-05 2.4e-05 2.2e-05 3.0e-05 3.2e-05 3.6e-05 3.1e-05\n",
      " 3.3e-05]\n",
      "execution_time_2: 1494 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: [0.000516 0.00056  0.000563 0.000567 0.000542 0.00054  0.000505 0.000545\n",
      " 0.000572 0.000568]\n",
      "execution_time_3: 3741 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: [12.921907 15.733155 16.122295 16.193801 16.16948  16.03718  15.693856\n",
      " 15.9009   15.554338 15.625999]\n",
      "execution_time_4: 3744 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: [15.84208  15.745937 16.095634 16.090122 15.978173 16.010525 15.52471\n",
      " 15.73008  15.273332 15.322104]\n",
      "execution_time_5: 1 unique values\n",
      "  ‚ñ∂Ô∏è Unique values: [0]\n",
      "code_size: 97 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: [18912 20344 18832 14792 18864 14744 20264 16224 20296 16176]\n",
      "\n",
      "üìà Descriptive Statistics:\n",
      "                                 count unique                         top  \\\n",
      "APP_NAME                          3840     30  linear-algebra/kernels/2mm   \n",
      "-funsafe-math-optimizations       3840      2                           X   \n",
      "-fno-guess-branch-probability     3840      2                           X   \n",
      "-fno-ivopts                       3840      2                           X   \n",
      "-fno-tree-loop-optimize           3840      2                           X   \n",
      "-fno-inline-functions             3840      2                           X   \n",
      "-funroll-all-loops                3840      2                           X   \n",
      "-O2                               3840      2                           X   \n",
      "execution_time_1                3840.0    NaN                         NaN   \n",
      "execution_time_2                3840.0    NaN                         NaN   \n",
      "execution_time_3                3840.0    NaN                         NaN   \n",
      "execution_time_4                3840.0    NaN                         NaN   \n",
      "execution_time_5                3840.0    NaN                         NaN   \n",
      "code_size                       3840.0    NaN                         NaN   \n",
      "\n",
      "                                freq        mean          std       min  \\\n",
      "APP_NAME                         128         NaN          NaN       NaN   \n",
      "-funsafe-math-optimizations     1920         NaN          NaN       NaN   \n",
      "-fno-guess-branch-probability   1920         NaN          NaN       NaN   \n",
      "-fno-ivopts                     1920         NaN          NaN       NaN   \n",
      "-fno-tree-loop-optimize         1920         NaN          NaN       NaN   \n",
      "-fno-inline-functions           1920         NaN          NaN       NaN   \n",
      "-funroll-all-loops              1920         NaN          NaN       NaN   \n",
      "-O2                             1920         NaN          NaN       NaN   \n",
      "execution_time_1                 NaN    0.000065     0.000101  0.000002   \n",
      "execution_time_2                 NaN    0.001408     0.002328  0.000014   \n",
      "execution_time_3                 NaN   21.276389    23.885891  0.002678   \n",
      "execution_time_4                 NaN    21.14058    23.634883  0.002743   \n",
      "execution_time_5                 NaN         0.0          0.0       0.0   \n",
      "code_size                        NaN  16098.0375  1670.903571   14712.0   \n",
      "\n",
      "                                     25%       50%        75%        max  \n",
      "APP_NAME                             NaN       NaN        NaN        NaN  \n",
      "-funsafe-math-optimizations          NaN       NaN        NaN        NaN  \n",
      "-fno-guess-branch-probability        NaN       NaN        NaN        NaN  \n",
      "-fno-ivopts                          NaN       NaN        NaN        NaN  \n",
      "-fno-tree-loop-optimize              NaN       NaN        NaN        NaN  \n",
      "-fno-inline-functions                NaN       NaN        NaN        NaN  \n",
      "-funroll-all-loops                   NaN       NaN        NaN        NaN  \n",
      "-O2                                  NaN       NaN        NaN        NaN  \n",
      "execution_time_1                0.000012  0.000028   0.000072   0.000559  \n",
      "execution_time_2                0.000097  0.000659   0.001041   0.010982  \n",
      "execution_time_3                0.169525  9.329945  38.990443  91.267363  \n",
      "execution_time_4                0.177446  9.485886  37.897067  91.429726  \n",
      "execution_time_5                     0.0       0.0        0.0        0.0  \n",
      "code_size                        14752.0   16160.0    16200.0    24480.0  \n",
      "\n",
      "üîó Correlation Matrix (numeric columns only):\n",
      "                  execution_time_1  execution_time_2  execution_time_3  \\\n",
      "execution_time_1          1.000000          0.974959          0.330699   \n",
      "execution_time_2          0.974959          1.000000          0.385555   \n",
      "execution_time_3          0.330699          0.385555          1.000000   \n",
      "execution_time_4          0.331204          0.386759          0.998978   \n",
      "execution_time_5               NaN               NaN               NaN   \n",
      "code_size                -0.082661         -0.092076         -0.009185   \n",
      "\n",
      "                  execution_time_4  execution_time_5  code_size  \n",
      "execution_time_1          0.331204               NaN  -0.082661  \n",
      "execution_time_2          0.386759               NaN  -0.092076  \n",
      "execution_time_3          0.998978               NaN  -0.009185  \n",
      "execution_time_4          1.000000               NaN  -0.009508  \n",
      "execution_time_5               NaN               NaN        NaN  \n",
      "code_size                -0.009508               NaN   1.000000  \n",
      "\n",
      "üíæ Memory Usage:\n",
      "Index                                132\n",
      "APP_NAME                          309120\n",
      "-funsafe-math-optimizations       274560\n",
      "-fno-guess-branch-probability     278400\n",
      "-fno-ivopts                       243840\n",
      "-fno-tree-loop-optimize           266880\n",
      "-fno-inline-functions             263040\n",
      "-funroll-all-loops                257280\n",
      "-O2                               228480\n",
      "execution_time_1                   30720\n",
      "execution_time_2                   30720\n",
      "execution_time_3                   30720\n",
      "execution_time_4                   30720\n",
      "execution_time_5                   30720\n",
      "code_size                          30720\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Done analyzing.\n",
      "\n",
      "\n",
      "üîç Reading dataset: micaTable.csv\n",
      "\n",
      "‚úÖ Basic Info:\n",
      "Shape: (90, 1)\n",
      "Columns: ['APPLICATION_NAME DATASET totInstruction ILP32 ILP64 ILP128 ILP256 total_ins_count_for_hpc_alignment totInstruction mem-read mem-write control-flow arithmetic floating-point stack shift string sse other nop InstrFootprint64 InstrFootprint4k DataFootprint64 DataFootprint4k mem_access memReuseDist0-2 memReuseDist2-4 memReuseDist4-8 memReuseDist8-16 memReuseDist16-32 memReuseDist32-64 memReuseDist64-128 memReuseDist128-256 memReuseDist256-512 memReuseDist512-1k memReuseDist1k-2k memReuseDist2k-4k memReuseDist4k-8k memReuseDist8k-16k memReuseDist16k-32k memReuseDist32k-64k memReuseDist64k-128k memReuseDist128k-256k memReuseDist256k-512k memReuseDist512k-00 GAg_mispred_cnt_4bits PAg_mispred_cnt_4bits GAs_mispred_cnt_4bits PAs_mispred_cnt_4bits GAg_mispred_cnt_8bits PAg_mispred_cnt_8bits GAs_mispred_cnt_8bits PAs_mispred_cnt_8bits GAg_mispred_cnt_12bits PAg_mispred_cnt_12bits GAs_mispred_cnt_12bits PAs_mispred_cnt_12bits total_brCount total_transactionCount total_takenCount total_num_ops instr_reg_cnt total_reg_use_cnt total_reg_age reg_age_cnt_1 reg_age_cnt_2 reg_age_cnt_4 reg_age_cnt_8 reg_age_cnt_16 reg_age_cnt_32 reg_age_cnt_64 mem_read_cnt mem_read_local_stride_0 mem_read_local_stride_8 mem_read_local_stride_64 mem_read_local_stride_512 mem_read_local_stride_4096 mem_read_local_stride_32768 mem_read_local_stride_262144 mem_read_global_stride_0 mem_read_global_stride_8 mem_read_global_stride_64 mem_read_global_stride_512 mem_read_global_stride_4096 mem_read_global_stride_32768 mem_read_global_stride_262144 mem_write_cnt mem_write_local_stride_0 mem_write_local_stride_8 mem_write_local_stride_64 mem_write_local_stride_512 mem_write_local_stride_4096 mem_write_local_stride_32768 mem_write_local_stride_262144 mem_write_global_stride_0 mem_write_global_stride_8 mem_write_global_stride_64 mem_write_global_stride_512 mem_write_global_stride_4096 mem_write_global_stride_32768 mem_write_global_stride_262144']\n",
      "\n",
      "üìä Data Types:\n",
      "APPLICATION_NAME DATASET totInstruction ILP32 ILP64 ILP128 ILP256 total_ins_count_for_hpc_alignment totInstruction mem-read mem-write control-flow arithmetic floating-point stack shift string sse other nop InstrFootprint64 InstrFootprint4k DataFootprint64 DataFootprint4k mem_access memReuseDist0-2 memReuseDist2-4 memReuseDist4-8 memReuseDist8-16 memReuseDist16-32 memReuseDist32-64 memReuseDist64-128 memReuseDist128-256 memReuseDist256-512 memReuseDist512-1k memReuseDist1k-2k memReuseDist2k-4k memReuseDist4k-8k memReuseDist8k-16k memReuseDist16k-32k memReuseDist32k-64k memReuseDist64k-128k memReuseDist128k-256k memReuseDist256k-512k memReuseDist512k-00 GAg_mispred_cnt_4bits PAg_mispred_cnt_4bits GAs_mispred_cnt_4bits PAs_mispred_cnt_4bits GAg_mispred_cnt_8bits PAg_mispred_cnt_8bits GAs_mispred_cnt_8bits PAs_mispred_cnt_8bits GAg_mispred_cnt_12bits PAg_mispred_cnt_12bits GAs_mispred_cnt_12bits PAs_mispred_cnt_12bits total_brCount total_transactionCount total_takenCount total_num_ops instr_reg_cnt total_reg_use_cnt total_reg_age reg_age_cnt_1 reg_age_cnt_2 reg_age_cnt_4 reg_age_cnt_8 reg_age_cnt_16 reg_age_cnt_32 reg_age_cnt_64 mem_read_cnt mem_read_local_stride_0 mem_read_local_stride_8 mem_read_local_stride_64 mem_read_local_stride_512 mem_read_local_stride_4096 mem_read_local_stride_32768 mem_read_local_stride_262144 mem_read_global_stride_0 mem_read_global_stride_8 mem_read_global_stride_64 mem_read_global_stride_512 mem_read_global_stride_4096 mem_read_global_stride_32768 mem_read_global_stride_262144 mem_write_cnt mem_write_local_stride_0 mem_write_local_stride_8 mem_write_local_stride_64 mem_write_local_stride_512 mem_write_local_stride_4096 mem_write_local_stride_32768 mem_write_local_stride_262144 mem_write_global_stride_0 mem_write_global_stride_8 mem_write_global_stride_64 mem_write_global_stride_512 mem_write_global_stride_4096 mem_write_global_stride_32768 mem_write_global_stride_262144    object\n",
      "dtype: object\n",
      "\n",
      "üßÆ Missing Values:\n",
      "APPLICATION_NAME DATASET totInstruction ILP32 ILP64 ILP128 ILP256 total_ins_count_for_hpc_alignment totInstruction mem-read mem-write control-flow arithmetic floating-point stack shift string sse other nop InstrFootprint64 InstrFootprint4k DataFootprint64 DataFootprint4k mem_access memReuseDist0-2 memReuseDist2-4 memReuseDist4-8 memReuseDist8-16 memReuseDist16-32 memReuseDist32-64 memReuseDist64-128 memReuseDist128-256 memReuseDist256-512 memReuseDist512-1k memReuseDist1k-2k memReuseDist2k-4k memReuseDist4k-8k memReuseDist8k-16k memReuseDist16k-32k memReuseDist32k-64k memReuseDist64k-128k memReuseDist128k-256k memReuseDist256k-512k memReuseDist512k-00 GAg_mispred_cnt_4bits PAg_mispred_cnt_4bits GAs_mispred_cnt_4bits PAs_mispred_cnt_4bits GAg_mispred_cnt_8bits PAg_mispred_cnt_8bits GAs_mispred_cnt_8bits PAs_mispred_cnt_8bits GAg_mispred_cnt_12bits PAg_mispred_cnt_12bits GAs_mispred_cnt_12bits PAs_mispred_cnt_12bits total_brCount total_transactionCount total_takenCount total_num_ops instr_reg_cnt total_reg_use_cnt total_reg_age reg_age_cnt_1 reg_age_cnt_2 reg_age_cnt_4 reg_age_cnt_8 reg_age_cnt_16 reg_age_cnt_32 reg_age_cnt_64 mem_read_cnt mem_read_local_stride_0 mem_read_local_stride_8 mem_read_local_stride_64 mem_read_local_stride_512 mem_read_local_stride_4096 mem_read_local_stride_32768 mem_read_local_stride_262144 mem_read_global_stride_0 mem_read_global_stride_8 mem_read_global_stride_64 mem_read_global_stride_512 mem_read_global_stride_4096 mem_read_global_stride_32768 mem_read_global_stride_262144 mem_write_cnt mem_write_local_stride_0 mem_write_local_stride_8 mem_write_local_stride_64 mem_write_local_stride_512 mem_write_local_stride_4096 mem_write_local_stride_32768 mem_write_local_stride_262144 mem_write_global_stride_0 mem_write_global_stride_8 mem_write_global_stride_64 mem_write_global_stride_512 mem_write_global_stride_4096 mem_write_global_stride_32768 mem_write_global_stride_262144    0\n",
      "dtype: int64\n",
      "\n",
      "üîë Unique Values Per Column:\n",
      "APPLICATION_NAME DATASET totInstruction ILP32 ILP64 ILP128 ILP256 total_ins_count_for_hpc_alignment totInstruction mem-read mem-write control-flow arithmetic floating-point stack shift string sse other nop InstrFootprint64 InstrFootprint4k DataFootprint64 DataFootprint4k mem_access memReuseDist0-2 memReuseDist2-4 memReuseDist4-8 memReuseDist8-16 memReuseDist16-32 memReuseDist32-64 memReuseDist64-128 memReuseDist128-256 memReuseDist256-512 memReuseDist512-1k memReuseDist1k-2k memReuseDist2k-4k memReuseDist4k-8k memReuseDist8k-16k memReuseDist16k-32k memReuseDist32k-64k memReuseDist64k-128k memReuseDist128k-256k memReuseDist256k-512k memReuseDist512k-00 GAg_mispred_cnt_4bits PAg_mispred_cnt_4bits GAs_mispred_cnt_4bits PAs_mispred_cnt_4bits GAg_mispred_cnt_8bits PAg_mispred_cnt_8bits GAs_mispred_cnt_8bits PAs_mispred_cnt_8bits GAg_mispred_cnt_12bits PAg_mispred_cnt_12bits GAs_mispred_cnt_12bits PAs_mispred_cnt_12bits total_brCount total_transactionCount total_takenCount total_num_ops instr_reg_cnt total_reg_use_cnt total_reg_age reg_age_cnt_1 reg_age_cnt_2 reg_age_cnt_4 reg_age_cnt_8 reg_age_cnt_16 reg_age_cnt_32 reg_age_cnt_64 mem_read_cnt mem_read_local_stride_0 mem_read_local_stride_8 mem_read_local_stride_64 mem_read_local_stride_512 mem_read_local_stride_4096 mem_read_local_stride_32768 mem_read_local_stride_262144 mem_read_global_stride_0 mem_read_global_stride_8 mem_read_global_stride_64 mem_read_global_stride_512 mem_read_global_stride_4096 mem_read_global_stride_32768 mem_read_global_stride_262144 mem_write_cnt mem_write_local_stride_0 mem_write_local_stride_8 mem_write_local_stride_64 mem_write_local_stride_512 mem_write_local_stride_4096 mem_write_local_stride_32768 mem_write_local_stride_262144 mem_write_global_stride_0 mem_write_global_stride_8 mem_write_global_stride_64 mem_write_global_stride_512 mem_write_global_stride_4096 mem_write_global_stride_32768 mem_write_global_stride_262144: 90 unique values\n",
      "  ‚ñ∂Ô∏è Showing first 10: ['2mm dataset1 326960 49338 41968 37029 33926 326604 326960 73265 27600 56769 201479 0 6068 3437 358 44383 12165 1121 2888 83 1068 60 73297 2559 32741 6362 6384 2627 15903 5397 499 248 159 151 250 17 0 0 0 0 0 0 0 5785 4731 5090 6243 7416 4616 5037 5305 10751 5314 4811 4914 52768 5651 4143 584929 199179 357729 402664 86684 108574 162316 236275 276501 297439 313355 73265 1071 34111 50538 64945 66753 67564 67730 73 16667 19445 21970 29195 52889 54561 27600 14 23471 24458 25450 25721 25783 25783 1 17180 24111 25887 26064 26149 26149'\n",
      " '2mm dataset2 2942160 420241 368940 350853 339831 2941804 2942160 651880 324973 350022 1697695 0 6068 3693 358 856494 19346 1264 4598 110 1122 61 651910 4268 281565 6243 6504 3072 2509 168744 141543 242 17247 19652 206 115 0 0 0 0 0 0 0 10498 9404 9780 10948 12149 9290 9727 9993 15475 9985 9493 9586 346024 14984 8809 5204705 1930532 3845249 4233323 871563 925588 1599187 2729226 3189878 3237242 3297821 651880 1071 319536 337899 480247 640089 646116 646316 73 16727 19860 22591 24608 222943 631500 324973 14 314959 319460 321432 323050 323114 323137 1 314353 321230 323009 323171 323251 323266'\n",
      " '2mm dataset3 14105281191 1835697306 1670931056 1665424286 1663057471 14105280905 14105281191 3313008955 1659651058 1658704913 8301772447 0 5958 3355 287 4140178309 2654280 6290 581390 9126 958 58 3313008985 581060 1448185193 6457 6179 2101 2403 3849 493 241 112 865229753 792249217 13 0 0 0 0 98876800 107865001 113 1690142 1689140 1689488 1690673 1691777 1689022 1689441 1689722 1695112 1689731 1689213 1689333 1658700969 3374594 1688588 24886125450 9128228107 16101058622 20687809295 4129520133 4141741852 7470353209 13382047056 15765139293 15774079666 15792182192 3313008955 1055 1655306029 1655322042 1655323206 1655324276 3311323396 3311323560 73 19934 22689 25124 26211 29042 30662 1659651058 14 1657693015 1659648911 1659649131 1659649370 1659649377 1659649377 1 1659633902 1659640678 1659642453 1659642600 1659642651 1659642651'\n",
      " '3mm dataset1 392129 57803 51175 45982 43022 391773 392129 89979 36590 65881 246114 0 6208 3560 358 54992 12638 1146 2998 86 1069 60 90010 2625 40416 6454 6280 3291 23443 5042 1620 251 168 151 252 17 0 0 0 0 0 0 0 6245 5129 5514 6753 7921 5009 5448 5785 11288 5707 5218 5333 61817 6427 4542 697322 237420 452443 503302 98519 120229 191293 325183 349762 372535 392333 89979 1079 42006 58460 81205 83369 84267 84431 73 16828 19636 22176 36015 69485 71105 36590 16 32353 33340 34373 34649 34758 34758 1 25996 33009 34791 34978 35078 35078'\n",
      " '3mm dataset2 4755776 634265 611881 594232 582307 4755420 4755776 1130832 569150 592873 2918794 0 6278 3702 358 1205212 19250 1299 5580 125 1186 62 1130862 4905 493794 6314 7488 2581 2609 159330 386850 245 31901 34510 181 150 4 0 0 0 0 0 0 13701 12534 12941 14169 15412 12427 12880 13193 18795 13123 12635 12739 588770 21230 11949 8343846 3014734 6299631 7042048 1229264 1280585 2438013 5179730 5245117 5308681 5395220 1130832 1080 553646 573642 697580 1115817 1121473 1125206 73 17172 20626 23482 28100 431489 1109241 569150 16 558213 561199 564113 567135 567215 567255 1 558197 565257 567046 567212 567299 567325'\n",
      " '3mm dataset3 21672470080 2724195618 2717880478 2712372191 2709787996 21672469794 21672470080 5400049440 2704656507 2703663805 13524340116 0 6074 3375 287 5437203909 5194653 7503 838895 13153 962 58 5400049471 728564 2362085449 6156 5970 2375 2707 3610 484 246 110 792349302 1907764070 13 0 0 0 0 188764700 148335600 115 2601374 2600344 2600723 2601977 2603038 2600226 2600664 2601006 2606367 2600938 2600424 2600556 2703659813 5196996 2599789 37928642187 13560492780 24705914887 32506397743 5427222778 5440029498 10857251563 24364393008 24379158908 24391816084 24418911492 5400049440 1055 2697437329 2697453413 2697454578 2697455648 5397453868 5397454032 73 20311 23080 25515 26711 29457 31077 2704656507 16 2702603366 2704654345 2704654565 2704654804 2704654811 2704654811 1 2704638619 2704645504 2704647289 2704647436 2704647487 2704647487'\n",
      " 'adi dataset1 569377 120205 109772 95271 74289 569021 569377 137198 54680 69268 306153 0 6006 3378 358 170005 11451 2202 2844 83 1004 59 137229 2506 55008 17338 34477 6292 7511 6911 960 5655 153 152 249 17 0 0 0 0 0 0 0 6525 5501 5826 6975 8139 5381 5787 6044 11466 6078 5569 5655 65299 7187 4907 965045 401271 746439 871206 208855 298830 410710 474276 543326 609060 626778 137198 1067 64164 107039 128301 130754 131511 131675 73 29351 32097 47515 74433 117005 118625 54680 13 34662 43047 52019 52870 52898 52898 1 2757 16051 24985 51819 53355 53355'\n",
      " 'adi dataset2 7818231 1912493 1874122 1800742 1668673 7817875 7818231 1934527 840495 585586 3693927 0 5998 3382 358 3503325 15371 8128 4428 109 1015 59 1934558 4079 726678 240504 592687 12616 33343 57303 159328 640 819 1609 104859 93 0 0 0 0 0 0 0 14452 13382 13720 14857 16095 13263 13679 13930 19406 13962 13460 13541 581610 22952 12788 12863870 6081906 11381016 13773155 3420837 4918460 6821176 7661033 8652077 9630322 9689685 1934527 1067 949035 1510146 1910369 1920564 1928786 1928996 73 285618 288368 559946 560943 1102179 1915803 840495 13 543066 685330 833342 835864 838660 838688 1 4331 145700 286592 286754 829745 839083'\n",
      " 'adi dataset3 27909017332 6971936160 6964818830 6949845811 6921899714 27909017046 27909017332 6973069829 2992517090 1993294382 12963399362 0 5729 3312 287 12949304066 1009853 1499994 502110 7890 905 58 6973069860 501529 2615778328 871758910 2179638063 1873823 5618118 8737100 18466444 36436241 74868109 191899150 427826670 165232508 6489 11978 24956 48913 98325 196650 374047556 2002414 2001771 2001818 2003066 2003814 2001638 2001719 2002180 2006948 2002036 2001540 2001671 1993290695 3999599 2000946 45848721293 21924429354 35379535320 49826117394 12452338783 17930631134 24902184270 27892468096 31386232592 34876257257 34886749198 6973069829 781 3483040913 5476556723 5476557738 5476558702 6971561413 6971561577 72 996019841 996021999 996024373 996025424 1992031913 1992033460 2992517090 12 1991019100 2491017072 2491017278 2491017507 2992011012 2992011012 1 501468 498510012 498511753 498511890 997510938 997510938'\n",
      " 'atax dataset1 227705 38011 31476 26832 24031 227309 227705 50853 16055 45023 142565 0 5998 3535 399 16800 10880 1161 2872 84 1036 60 51265 2539 25214 6798 6353 2368 2885 3796 501 249 148 152 245 17 0 0 0 0 0 0 0 5112 4081 4368 5450 6702 3959 4348 4564 9918 4658 4146 4215 41061 4377 3496 407672 134806 223084 260949 58994 85273 113268 146582 167218 185681 196606 50853 1065 25685 41956 43290 44410 45163 45329 73 16558 19301 21755 23068 30693 32365 16055 14 11896 12884 13942 14220 14249 14249 1 5796 12598 14378 14590 14705 14705']\n",
      "\n",
      "üìà Descriptive Statistics:\n",
      "                                                   count unique  \\\n",
      "APPLICATION_NAME DATASET totInstruction ILP32 I...    90     90   \n",
      "\n",
      "                                                                                                  top  \\\n",
      "APPLICATION_NAME DATASET totInstruction ILP32 I...  2mm dataset1 326960 49338 41968 37029 33926 32...   \n",
      "\n",
      "                                                   freq  \n",
      "APPLICATION_NAME DATASET totInstruction ILP32 I...    1  \n",
      "\n",
      "üîó Correlation Matrix (numeric columns only):\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "üíæ Memory Usage:\n",
      "Index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          132\n",
      "APPLICATION_NAME DATASET totInstruction ILP32 ILP64 ILP128 ILP256 total_ins_count_for_hpc_alignment totInstruction mem-read mem-write control-flow arithmetic floating-point stack shift string sse other nop InstrFootprint64 InstrFootprint4k DataFootprint64 DataFootprint4k mem_access memReuseDist0-2 memReuseDist2-4 memReuseDist4-8 memReuseDist8-16 memReuseDist16-32 memReuseDist32-64 memReuseDist64-128 memReuseDist128-256 memReuseDist256-512 memReuseDist512-1k memReuseDist1k-2k memReuseDist2k-4k memReuseDist4k-8k memReuseDist8k-16k memReuseDist16k-32k memReuseDist32k-64k memReuseDist64k-128k memReuseDist128k-256k memReuseDist256k-512k memReuseDist512k-00 GAg_mispred_cnt_4bits PAg_mispred_cnt_4bits GAs_mispred_cnt_4bits PAs_mispred_cnt_4bits GAg_mispred_cnt_8bits PAg_mispred_cnt_8bits GAs_mispred_cnt_8bits PAs_mispred_cnt_8bits GAg_mispred_cnt_12bits PAg_mispred_cnt_12bits GAs_mispred_cnt_12bits PAs_mispred_cnt_12bits total_brCount total_transactionCount total_takenCount total_num_ops instr_reg_cnt total_reg_use_cnt total_reg_age reg_age_cnt_1 reg_age_cnt_2 reg_age_cnt_4 reg_age_cnt_8 reg_age_cnt_16 reg_age_cnt_32 reg_age_cnt_64 mem_read_cnt mem_read_local_stride_0 mem_read_local_stride_8 mem_read_local_stride_64 mem_read_local_stride_512 mem_read_local_stride_4096 mem_read_local_stride_32768 mem_read_local_stride_262144 mem_read_global_stride_0 mem_read_global_stride_8 mem_read_global_stride_64 mem_read_global_stride_512 mem_read_global_stride_4096 mem_read_global_stride_32768 mem_read_global_stride_262144 mem_write_cnt mem_write_local_stride_0 mem_write_local_stride_8 mem_write_local_stride_64 mem_write_local_stride_512 mem_write_local_stride_4096 mem_write_local_stride_32768 mem_write_local_stride_262144 mem_write_global_stride_0 mem_write_global_stride_8 mem_write_global_stride_64 mem_write_global_stride_512 mem_write_global_stride_4096 mem_write_global_stride_32768 mem_write_global_stride_262144    63942\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Done analyzing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_dataset(file_path, max_unique_display=10):\n",
    "    print(f\"\\nüîç Reading dataset: {file_path}\")\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    print(\"\\n‚úÖ Basic Info:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "    print(\"\\nüìä Data Types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\nüßÆ Missing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    print(\"\\nüîë Unique Values Per Column:\")\n",
    "    for col in df.columns:\n",
    "        unique_count = df[col].nunique(dropna=False)\n",
    "        print(f\"{col}: {unique_count} unique values\")\n",
    "        if unique_count <= max_unique_display:\n",
    "            print(f\"  ‚ñ∂Ô∏è Unique values: {df[col].unique().tolist()}\")\n",
    "        else:\n",
    "            print(f\"  ‚ñ∂Ô∏è Showing first {max_unique_display}: {df[col].unique()[:max_unique_display]}\")\n",
    "\n",
    "    print(\"\\nüìà Descriptive Statistics:\")\n",
    "    print(df.describe(include='all').transpose())\n",
    "\n",
    "    print(\"\\nüîó Correlation Matrix (numeric columns only):\")\n",
    "    print(df.corr(numeric_only=True))\n",
    "\n",
    "    print(\"\\nüíæ Memory Usage:\")\n",
    "    print(df.memory_usage(deep=True))\n",
    "\n",
    "    print(\"\\n‚úÖ Done analyzing.\\n\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your dataset paths\n",
    "    analyze_dataset(\"exec_times.csv\")\n",
    "    analyze_dataset(\"micaTable.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1085f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reward curve saved at: reward_curves\\linear-algebra/kernels/2mm_reward_curve.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def _plot_rewards(benchmark_name, rewards):\n",
    "    \"\"\"Plot and save reward curve for each benchmark\"\"\"\n",
    "    # Create the output path like: reward_curves/linear-algebra/kernels/2mm_reward_curve.png\n",
    "    output_path = os.path.join(\"reward_curves\", f\"{benchmark_name}_reward_curve.png\")\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Plot reward curve\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(rewards, label=\"Episode Reward\", color=\"blue\")\n",
    "    plt.title(f\"Reward Curve - {benchmark_name}\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"‚úÖ Reward curve saved at: {output_path}\")\n",
    "\n",
    "# ------------------------------------\n",
    "# ‚úÖ Simulated reward data\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark = \"linear-algebra/kernels/2mm\"\n",
    "\n",
    "    # Simulate 500 episode rewards with noise, improving over time\n",
    "    np.random.seed(42)\n",
    "    base_reward = np.linspace(10, 120, 500)  # Linearly increasing reward\n",
    "    noise = np.random.normal(0, 5, size=500)  # Small random noise\n",
    "    rewards = base_reward + noise\n",
    "\n",
    "    _plot_rewards(benchmark, rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed. Installing PyTorch with CUDA support...\")\n",
    "    # subprocess.check_call([\n",
    "    #     \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"\n",
    "    # ])\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available after install: {cuda_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d905ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed. Installing PyTorch with CUDA support...\")\n",
    "    # subprocess.check_call([\n",
    "    #     \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"\n",
    "    # ])\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available after install: {cuda_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# File: trainer.py\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from compiler_environment import CompilerEnvironment\n",
    "from dqn_agent import DQNAgent\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CompilerOptimizationTrainer:\n",
    "    \"\"\"Main trainer class for RL compiler optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str = \"data/exec_times.csv\"):\n",
    "        self.data_path = data_path\n",
    "        self.preprocessor = DataPreprocessor(data_path)\n",
    "        self.benchmark_data = None\n",
    "        self.agents = {}\n",
    "        self.environments = {}\n",
    "        self.training_stats = defaultdict(list)\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"Setup data and create agents/environments\"\"\"\n",
    "        logger.info(\"Setting up trainer...\")\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        self.benchmark_data = self.preprocessor.preprocess_data()\n",
    "        \n",
    "        if not self.benchmark_data:\n",
    "            raise ValueError(\"No benchmark data available after preprocessing!\")\n",
    "        \n",
    "        # Create agents and environments for each benchmark\n",
    "        for benchmark_name in self.benchmark_data.keys():\n",
    "            logger.info(f\"Setting up agent for benchmark: {benchmark_name}\")\n",
    "            \n",
    "            # Create environment\n",
    "            env = CompilerEnvironment(self.benchmark_data, benchmark_name)\n",
    "            self.environments[benchmark_name] = env\n",
    "            \n",
    "            # Create agent\n",
    "            state_size = env.observation_space.shape[0]\n",
    "            \n",
    "            agent = DQNAgent(\n",
    "                state_size=state_size,\n",
    "                action_size=7,  # 7 compiler flags\n",
    "                lr=0.001,\n",
    "                gamma=0.95,\n",
    "                epsilon=1.0,\n",
    "                epsilon_min=0.01,\n",
    "                epsilon_decay=0.995,\n",
    "                memory_size=10000,\n",
    "                batch_size=32,\n",
    "                target_update=100\n",
    "            )\n",
    "            \n",
    "            self.agents[benchmark_name] = agent\n",
    "            \n",
    "        logger.info(f\"Setup complete for {len(self.benchmark_data)} benchmarks\")\n",
    "    \n",
    "    def train_single_benchmark(self, benchmark_name: str, episodes: int = 1000, \n",
    "                             save_frequency: int = 100, verbose: bool = True):\n",
    "        \"\"\"Train agent on a single benchmark\"\"\"\n",
    "        \n",
    "        if benchmark_name not in self.agents:\n",
    "            logger.error(f\"No agent found for benchmark: {benchmark_name}\")\n",
    "            return\n",
    "        \n",
    "        agent = self.agents[benchmark_name]\n",
    "        env = self.environments[benchmark_name]\n",
    "        \n",
    "        logger.info(f\"Training {benchmark_name} for {episodes} episodes...\")\n",
    "        \n",
    "        episode_rewards = []\n",
    "        episode_improvements = []\n",
    "        episode_losses = []\n",
    "        best_configs = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()\n",
    "            total_reward = 0\n",
    "            episode_loss = []\n",
    "            \n",
    "            while True:\n",
    "                # Choose action\n",
    "                action = agent.act(state, training=True)\n",
    "                \n",
    "                # Take step\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                \n",
    "                # Store experience\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                \n",
    "                # Train agent\n",
    "                loss = agent.replay()\n",
    "                if loss is not None:\n",
    "                    episode_loss.append(loss)\n",
    "                \n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # Track statistics\n",
    "            episode_rewards.append(total_reward)\n",
    "            episode_improvements.append(info['improvement'])\n",
    "            if episode_loss:\n",
    "                episode_losses.append(np.mean(episode_loss))\n",
    "            \n",
    "            # Track best configuration found\n",
    "            if info['improvement'] > 0:  # Only if we found an improvement\n",
    "                best_configs.append({\n",
    "                    'episode': episode,\n",
    "                    'config': info['config'].tolist(),\n",
    "                    'improvement': info['improvement'],\n",
    "                    'execution_time': info['execution_time']\n",
    "                })\n",
    "            \n",
    "            # Logging\n",
    "            if verbose and (episode + 1) % 50 == 0:\n",
    "                avg_reward = np.mean(episode_rewards[-50:])\n",
    "                avg_improvement = np.mean(episode_improvements[-50:])\n",
    "                current_eps = agent.epsilon\n",
    "                \n",
    "                logger.info(f\"  Episode {episode + 1}/{episodes} - \"\n",
    "                           f\"Avg Reward: {avg_reward:.2f}, \"\n",
    "                           f\"Avg Improvement: {avg_improvement:.4f}, \"\n",
    "                           f\"Epsilon: {current_eps:.3f}\")\n",
    "            \n",
    "            # Save model periodically\n",
    "            if (episode + 1) % save_frequency == 0:\n",
    "                model_path = f\"models/{benchmark_name}_episode_{episode + 1}.pth\"\n",
    "                os.makedirs(\"models\", exist_ok=True)\n",
    "                agent.save(model_path)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Store training statistics\n",
    "        self.training_stats[benchmark_name] = {\n",
    "            'episode_rewards': episode_rewards,\n",
    "            'episode_improvements': episode_improvements,\n",
    "            'episode_losses': episode_losses,\n",
    "            'best_configs': best_configs,\n",
    "            'training_time': training_time,\n",
    "            'final_epsilon': agent.epsilon\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Training completed for {benchmark_name} in {training_time:.2f} seconds\")\n",
    "        \n",
    "        # Save final model\n",
    "        final_model_path = f\"models/{benchmark_name}_final.pth\"\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        agent.save(final_model_path)\n",
    "        \n",
    "        return self.training_stats[benchmark_name]\n",
    "    \n",
    "    def train_all_benchmarks(self, episodes: int = 1000, save_frequency: int = 100):\n",
    "        \"\"\"Train agents on all benchmarks\"\"\"\n",
    "        logger.info(f\"Training all {len(self.benchmark_data)} benchmarks...\")\n",
    "        \n",
    "        for benchmark_name in self.benchmark_data.keys():\n",
    "            logger.info(f\"\\n{'='*60}\")\n",
    "            logger.info(f\"Training benchmark: {benchmark_name}\")\n",
    "            logger.info(f\"{'='*60}\")\n",
    "            \n",
    "            try:\n",
    "                self.train_single_benchmark(\n",
    "                    benchmark_name, episodes, save_frequency, verbose=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error training {benchmark_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(\"Training completed for all benchmarks\")\n",
    "    \n",
    "    def evaluate_benchmark(self, benchmark_name: str, episodes: int = 100):\n",
    "        \"\"\"Evaluate trained agent on benchmark\"\"\"\n",
    "        if benchmark_name not in self.agents:\n",
    "            logger.error(f\"No trained agent found for benchmark: {benchmark_name}\")\n",
    "            return None\n",
    "        \n",
    "        agent = self.agents[benchmark_name]\n",
    "        env = self.environments[benchmark_name]\n",
    "        \n",
    "        logger.info(f\"Evaluating {benchmark_name} for {episodes} episodes...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()\n",
    "            \n",
    "            while True:\n",
    "                # Use greedy policy (no exploration)\n",
    "                action = agent.act(state, training=False)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "                if done:\n",
    "                    results.append({\n",
    "                        'episode': episode,\n",
    "                        'config': info['config'].tolist(),\n",
    "                        'execution_time': info['execution_time'],\n",
    "                        'improvement': info['improvement'],\n",
    "                        'reward': reward\n",
    "                    })\n",
    "                    break\n",
    "        \n",
    "        # Calculate statistics\n",
    "        improvements = [r['improvement'] for r in results]\n",
    "        execution_times = [r['execution_time'] for r in results]\n",
    "        \n",
    "        evaluation_stats = {\n",
    "            'mean_improvement': np.mean(improvements),\n",
    "            'std_improvement': np.std(improvements),\n",
    "            'best_improvement': np.max(improvements),\n",
    "            'mean_execution_time': np.mean(execution_times),\n",
    "            'best_execution_time': np.min(execution_times),\n",
    "            'baseline_time': env.baseline_time,\n",
    "            'best_known_time': env.best_time,\n",
    "            'results': results\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Evaluation results for {benchmark_name}:\")\n",
    "        logger.info(f\"  Mean improvement: {evaluation_stats['mean_improvement']:.4f}\")\n",
    "        logger.info(f\"  Best improvement: {evaluation_stats['best_improvement']:.4f}\")\n",
    "        logger.info(f\"  Best execution time: {evaluation_stats['best_execution_time']:.6f}\")\n",
    "        logger.info(f\"  Baseline time: {evaluation_stats['baseline_time']:.6f}\")\n",
    "        \n",
    "        return evaluation_stats\n",
    "    \n",
    "    def visualize_training_progress(self, benchmark_name: str = None, save_plots: bool = True):\n",
    "        \"\"\"Visualize training progress\"\"\"\n",
    "        if benchmark_name:\n",
    "            benchmarks_to_plot = [benchmark_name]\n",
    "        else:\n",
    "            benchmarks_to_plot = list(self.training_stats.keys())\n",
    "        \n",
    "        for benchmark in benchmarks_to_plot:\n",
    "            if benchmark not in self.training_stats:\n",
    "                logger.warning(f\"No training stats found for {benchmark}\")\n",
    "                continue\n",
    "            \n",
    "            stats = self.training_stats[benchmark]\n",
    "            \n",
    "            # Create subplots\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            fig.suptitle(f'Training Progress: {benchmark}', fontsize=16)\n",
    "            \n",
    "            # Plot 1: Episode Rewards\n",
    "            axes[0, 0].plot(stats['episode_rewards'])\n",
    "            axes[0, 0].set_title('Episode Rewards')\n",
    "            axes[0, 0].set_xlabel('Episode')\n",
    "            axes[0, 0].set_ylabel('Total Reward')\n",
    "            axes[0, 0].grid(True)\n",
    "            \n",
    "            # Plot 2: Episode Improvements\n",
    "            axes[0, 1].plot(stats['episode_improvements'])\n",
    "            axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "            axes[0, 1].set_title('Performance Improvements')\n",
    "            axes[0, 1].set_xlabel('Episode')\n",
    "            axes[0, 1].set_ylabel('Improvement Ratio')\n",
    "            axes[0, 1].grid(True)\n",
    "            \n",
    "            # Plot 3: Training Losses\n",
    "            if stats['episode_losses']:\n",
    "                axes[1, 0].plot(stats['episode_losses'])\n",
    "                axes[1, 0].set_title('Training Loss')\n",
    "                axes[1, 0].set_xlabel('Episode')\n",
    "                axes[1, 0].set_ylabel('Loss')\n",
    "                axes[1, 0].grid(True)\n",
    "            else:\n",
    "                axes[1, 0].text(0.5, 0.5, 'No Loss Data', ha='center', va='center')\n",
    "                axes[1, 0].set_title('Training Loss')\n",
    "            \n",
    "            # Plot 4: Best Configurations Over Time\n",
    "            if stats['best_configs']:\n",
    "                episodes = [c['episode'] for c in stats['best_configs']]\n",
    "                improvements = [c['improvement'] for c in stats['best_configs']]\n",
    "                axes[1, 1].scatter(episodes, improvements, alpha=0.6)\n",
    "                axes[1, 1].set_title('Best Configurations Found')\n",
    "                axes[1, 1].set_xlabel('Episode')\n",
    "                axes[1, 1].set_ylabel('Improvement')\n",
    "                axes[1, 1].grid(True)\n",
    "            else:\n",
    "                axes[1, 1].text(0.5, 0.5, 'No Improvements Found', ha='center', va='center')\n",
    "                axes[1, 1].set_title('Best Configurations Found')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_plots:\n",
    "                os.makedirs(\"plots\", exist_ok=True)\n",
    "                plt.savefig(f\"plots/{benchmark}_training_progress.png\", dpi=300, bbox_inches='tight')\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    def save_results(self, filepath: str = \"results/training_results.json\"):\n",
    "        \"\"\"Save training results to file\"\"\"\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        \n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        results_to_save = {}\n",
    "        for benchmark, stats in self.training_stats.items():\n",
    "            results_to_save[benchmark] = {\n",
    "                'episode_rewards': [float(x) for x in stats['episode_rewards']],\n",
    "                'episode_improvements': [float(x) for x in stats['episode_improvements']],\n",
    "                'episode_losses': [float(x) for x in stats['episode_losses']],\n",
    "                'best_configs': stats['best_configs'],\n",
    "                'training_time': stats['training_time'],\n",
    "                'final_epsilon': stats['final_epsilon']\n",
    "            }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(results_to_save, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Results saved to {filepath}\")\n",
    "    \n",
    "    def load_results(self, filepath: str = \"results/training_results.json\"):\n",
    "        \"\"\"Load training results from file\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                results = json.load(f)\n",
    "            \n",
    "            # Convert back to numpy arrays if needed\n",
    "            for benchmark, stats in results.items():\n",
    "                self.training_stats[benchmark] = stats\n",
    "            \n",
    "            logger.info(f\"Results loaded from {filepath}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading results: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_summary_report(self):\n",
    "        \"\"\"Generate summary report of all training results\"\"\"\n",
    "        if not self.training_stats:\n",
    "            logger.warning(\"No training statistics available\")\n",
    "            return None\n",
    "        \n",
    "        report = {\n",
    "            'total_benchmarks': len(self.training_stats),\n",
    "            'benchmark_results': {}\n",
    "        }\n",
    "        \n",
    "        for benchmark, stats in self.training_stats.items():\n",
    "            benchmark_summary = {\n",
    "                'episodes_trained': len(stats['episode_rewards']),\n",
    "                'final_avg_reward': np.mean(stats['episode_rewards'][-50:]) if len(stats['episode_rewards']) >= 50 else np.mean(stats['episode_rewards']),\n",
    "                'best_improvement_found': max([c['improvement'] for c in stats['best_configs']]) if stats['best_configs'] else 0,\n",
    "                'num_improvements_found': len(stats['best_configs']),\n",
    "                'training_time_minutes': stats['training_time'] / 60,\n",
    "                'final_epsilon': stats['final_epsilon']\n",
    "            }\n",
    "            \n",
    "            report['benchmark_results'][benchmark] = benchmark_summary\n",
    "        \n",
    "        # Overall statistics\n",
    "        all_improvements = []\n",
    "        for stats in self.training_stats.values():\n",
    "            if stats['best_configs']:\n",
    "                all_improvements.extend([c['improvement'] for c in stats['best_configs']])\n",
    "        \n",
    "        if all_improvements:\n",
    "            report['overall_stats'] = {\n",
    "                'benchmarks_with_improvements': sum(1 for stats in self.training_stats.values() if stats['best_configs']),\n",
    "                'total_improvements_found': len(all_improvements),\n",
    "                'mean_improvement': np.mean(all_improvements),\n",
    "                'best_overall_improvement': max(all_improvements)\n",
    "            }\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# File: main.py\n",
    "# ==========================================\n",
    "\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "from trainer import CompilerOptimizationTrainer\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Setup logging configuration\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.StreamHandler(),\n",
    "            logging.FileHandler('compiler_optimization.log')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Compiler Flag Optimization with RL')\n",
    "    parser.add_argument('--data_path', type=str, default='data/exec_times.csv',\n",
    "                       help='Path to the execution times CSV file')\n",
    "    parser.add_argument('--episodes', type=int, default=1000,\n",
    "                       help='Number of training episodes per benchmark')\n",
    "    parser.add_argument('--benchmark', type=str, default=None,\n",
    "                       help='Specific benchmark to train (if None, trains all)')\n",
    "    parser.add_argument('--evaluate', action='store_true',\n",
    "                       help='Run evaluation after training')\n",
    "    parser.add_argument('--visualize', action='store_true',\n",
    "                       help='Generate training visualizations')\n",
    "    parser.add_argument('--load_results', type=str, default=None,\n",
    "                       help='Load previous results from JSON file')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Setup logging\n",
    "    setup_logging()\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    logger.info(\"Starting Compiler Flag Optimization with Reinforcement Learning\")\n",
    "    logger.info(f\"Data path: {args.data_path}\")\n",
    "    logger.info(f\"Episodes: {args.episodes}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize trainer\n",
    "        trainer = CompilerOptimizationTrainer(args.data_path)\n",
    "        \n",
    "        # Load previous results if specified\n",
    "        if args.load_results:\n",
    "            trainer.load_results(args.load_results)\n",
    "        \n",
    "        # Setup trainer (load data and create agents)\n",
    "        trainer.setup()\n",
    "        \n",
    "        # Training\n",
    "        if args.benchmark:\n",
    "            # Train specific benchmark\n",
    "            logger.info(f\"Training specific benchmark: {args.benchmark}\")\n",
    "            trainer.train_single_benchmark(args.benchmark, args.episodes)\n",
    "        else:\n",
    "            # Train all benchmarks\n",
    "            logger.info(\"Training all benchmarks\")\n",
    "            trainer.train_all_benchmarks(args.episodes)\n",
    "        \n",
    "        # Save results\n",
    "        trainer.save_results()\n",
    "        \n",
    "        # Evaluation\n",
    "        if args.evaluate:\n",
    "            logger.info(\"Running evaluation...\")\n",
    "            for benchmark in trainer.benchmark_data.keys():\n",
    "                trainer.evaluate_benchmark(benchmark, episodes=100)\n",
    "        \n",
    "        # Visualization\n",
    "        if args.visualize:\n",
    "            logger.info(\"Generating visualizations...\")\n",
    "            trainer.visualize_training_progress()\n",
    "        \n",
    "        # Summary report\n",
    "        report = trainer.get_summary_report()\n",
    "        if report:\n",
    "            logger.info(\"Training Summary Report:\")\n",
    "            logger.info(f\"  Total benchmarks: {report['total_benchmarks']}\")\n",
    "            if 'overall_stats' in report:\n",
    "                logger.info(f\"  Benchmarks with improvements: {report['overall_stats']['benchmarks_with_improvements']}\")\n",
    "                logger.info(f\"  Best overall improvement: {report['overall_stats']['best_overall_improvement']:.4f}\")\n",
    "        \n",
    "        logger.info(\"Compiler optimization training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during training: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# File: requirements.txt\n",
    "# ==========================================\n",
    "\n",
    "torch>=1.9.0\n",
    "numpy>=1.21.0\n",
    "pandas>=1.3.0\n",
    "scikit-learn>=1.0.0\n",
    "matplotlib>=3.4.0\n",
    "seaborn>=0.11.0\n",
    "gym>=0.21.0\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# File: run_training.py\n",
    "# ==========================================\n",
    "\n",
    "\"\"\"\n",
    "Simple script to run the compiler optimization training\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from trainer import CompilerOptimizationTrainer\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def run_training():\n",
    "    \"\"\"Run the complete training pipeline\"\"\"\n",
    "    \n",
    "    # Check if data file exists\n",
    "    data_path = \"data/exec_times.csv\"\n",
    "    if not os.path.exists(data_path):\n",
    "        logger.error(f\"Data file not found: {data_path}\")\n",
    "        logger.error(\"Please ensure the PolyBench execution data is available\")\n",
    "        return\n",
    "    \n",
    "    # Initialize trainer\n",
    "    logger.info(\"Initializing trainer...\")\n",
    "    trainer = CompilerOptimizationTrainer(data_path)\n",
    "    \n",
    "    # Setup (load data and create agents)\n",
    "    logger.info(\"Setting up data and agents...\")\n",
    "    trainer.setup()\n",
    "    \n",
    "    # Train on all benchmarks\n",
    "    logger.info(\"Starting training...\")\n",
    "    trainer.train_all_benchmarks(episodes=500)  # Reduced episodes for faster testing\n",
    "    \n",
    "    # Save results\n",
    "    logger.info(\"Saving results...\")\n",
    "    trainer.save_results()\n",
    "    \n",
    "    # Run evaluation\n",
    "    logger.info(\"Running evaluation...\")\n",
    "    for benchmark in list(trainer.benchmark_data.keys())[:3]:  # Evaluate first 3 benchmarks\n",
    "        trainer.evaluate_benchmark(benchmark, episodes=50)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    logger.info(\"Generating visualizations...\")\n",
    "    trainer.visualize_training_progress()\n",
    "    \n",
    "    # Print summary\n",
    "    report = trainer.get_summary_report()\n",
    "    if report:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TRAINING SUMMARY REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total benchmarks trained: {report['total_benchmarks']}\")\n",
    "        \n",
    "        if 'overall_stats' in report:\n",
    "            print(f\"Benchmarks with improvements: {report['overall_stats']['benchmarks_with_improvements']}\")\n",
    "            print(f\"Total improvements found: {report['overall_stats']['total_improvements_found']}\")\n",
    "            print(f\"Best overall improvement: {report['overall_stats']['best_overall_improvement']:.4f}\")\n",
    "            print(f\"Mean improvement: {report['overall_stats']['mean_improvement']:.4f}\")\n",
    "        \n",
    "        print(\"\\nPer-benchmark results:\")\n",
    "        for benchmark, results in report['benchmark_results'].items():\n",
    "            print(f\"  {benchmark}:\")\n",
    "            print(f\"    Best improvement: {results['best_improvement_found']:.4f}\")\n",
    "            print(f\"    Improvements found: {results['num_improvements_found']}\")\n",
    "            print(f\"    Training time: {results['training_time_minutes']:.2f} minutes\")\n",
    "    \n",
    "    logger.info(\"Training completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
